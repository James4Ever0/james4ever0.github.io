<!DOCTYPE html>
<html lang="en">

<head>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="google-site-verification" content="b_DAfR9nm03bD5lQ9kwfbSSh7WWVjfmhQ3TeecK3-mA" />
    <meta name="msvalidate.01" content="F37C07602C579EBF07A614E51E186EB7" />
    <meta name="sogou_site_verification" content="FaMs1nxxrL" /> 
    <link rel="stylesheet" href="github-markdown.css">
    <style>
        .markdown-body {
            box-sizing: border-box;
            min-width: 200px;
            max-width: 980px;
            margin: 0 auto;
            padding: 45px;
        }

        @media (max-width: 767px) {
            .markdown-body {
                padding: 15px;
            }
        }
    </style>
</head>

<body>
    <article class="markdown-body">
<h1>The shelf</h1>
<p>Collection of automated documentation.</p>
<p>Generated with <a href="https://github.com/james4ever0/prometheus">prometheus</a></p>
<ul>
<li>Cybergod (Autonomous Computer)<ul>
<li><a href="https://james4ever0.github.io/AppAgent">AppAgent</a> Multimodal Agents as Smartphone Users, an LLM-based multimodal agent framework designed to operate smartphone apps. </li>
<li><a href="https://james4ever0.github.io/CogVLM">CogVLM</a> a state-of-the-art-level open visual language model | 多模态预训练模型 </li>
<li><a href="https://james4ever0.github.io/cybergod_doc">cybergod</a> Autonomous computer program that can do anything without human operators. </li>
<li><a href="https://james4ever0.github.io/gpt4v-browsing">gpt4v-browsing</a> Web Scraping with GPT-4 Vision API and Puppeteer </li>
<li><a href="https://james4ever0.github.io/gpt-eyes">gpt-eyes</a> I GAVE GPT-4 EYES! </li>
<li><a href="https://james4ever0.github.io/GPT-4V-Act">GPT-4V-Act</a> AI agent using GPT-4V(ision) capable of using a mouse/keyboard to interact with web UI </li>
<li><a href="https://james4ever0.github.io/self-operating-computer">self-operating-computer</a> A framework to enable multimodal models to operate a computer. </li>
<li><a href="https://james4ever0.github.io/SingularGPT">SingularGPT</a> - Automate device by ChatGPT , Make your device more like a human.</li>
<li><a href="https://james4ever0.github.io/Video-Pre-Training">Video-Pre-Training</a> (VPT) Learning to Act by Watching Unlabeled Online Videos </li>
</ul>
</li>
<li>Image models<ul>
<li><a href="https://james4ever0.github.io/CLIP">CLIP</a> (Contrastive Language-Image Pretraining), Predict the most relevant text snippet given an image </li>
<li><a href="https://james4ever0.github.io/DALL-E">DALL-E</a> PyTorch package for the discrete VAE used for DALL·E. </li>
<li><a href="https://james4ever0.github.io/DALLE2-pytorch">DALLE2-pytorch</a>  OpenAI's updated text-to-image synthesis neural network, in Pytorch</li>
</ul>
</li>
<li>Utils<ul>
<li><a href="https://james4ever0.github.io/git_atomic_commit">git_atomic_commit</a> To fix any issue detected by <code>git fsck</code> caused by any git operation, once for all</li>
<li><a href="https://james4ever0.github.io/lazero">lazero</a> AGI helper libraries, may help for AGI developments and researches, similar to google's automl-zero </li>
</ul>
</li>
<li>Q* (Q-Star)<ul>
<li><a href="https://james4ever0.github.io/q-transformer">q-transformer</a> Scalable Offline Reinforcement Learning via Autoregressive Q-Functions, out of Google Deepmind</li>
<li><a href="https://james4ever0.github.io/open_qstar">open_qstar</a> Transformer-based LLM structurally infused with Q-Learning and A* heuristic search algorithms </li>
<li><a href="https://james4ever0.github.io/q-star">q-star</a> A reinforcement learning-based framework for intelligent agents using Microsoft AutoGen.</li>
<li><a href="https://james4ever0.github.io/mcts-for-llm">mcts-for-llm</a> This is a pip package implementing Reinforcement Learning algorithms in non-stationary environments supported by the OpenAI Gym toolkit. </li>
</ul>
</li>
<li>Superalignment<ul>
<li><a href="https://james4ever0.github.io/automated-interpretability">automated-interpretability</a> Language models can explain neurons in language models</li>
<li><a href="https://james4ever0.github.io/weak-to-strong">weak-to-strong</a> Can weak
model supervision elicit the full capabilities of a much stronger model?</li>
</ul>
</li>
<li>Audio models<ul>
<li><a href="https://james4ever0.github.io/whisper">whisper</a> Robust Speech Recognition via Large-Scale Weak Supervision</li>
</ul>
</li>
<li>Tree of Thoughts<ul>
<li><a href="https://james4ever0.github.io/graph-of-thoughts">graph-of-thoughts</a> Solving Elaborate Problems with Large Language Models</li>
<li><a href="https://james4ever0.github.io/lmql-tree-of-thoughts">lmql-tree-of-thoughts</a> LMQL implementation of tree of thoughts </li>
<li><a href="https://james4ever0.github.io/tree-of-thoughts">tree-of-thoughts</a> Deliberate Problem Solving with Large Language Models that Elevates Model Reasoning by at least 70%</li>
<li><a href="https://james4ever0.github.io/LLM_Tree_Search">LLM_Tree_Search</a> Alphazero-like Tree-Search can guide large language model decoding and training </li>
</ul>
</li>
<li>Embodied Intelligence<ul>
<li><a href="https://james4ever0.github.io/Voyager">Voyager</a> An Open-Ended Embodied Agent with Large Language Models </li>
<li><a href="https://james4ever0.github.io/RoboGen">RoboGen</a> A generative and self-guided robotic agent that endlessly propose and master new skills. </li>
</ul>
</li>
<li>Media content automation<ul>
<li><a href="https://james4ever0.github.io/vced">vced</a> 通过你的文字描述来自动识别视频中相符合的片段进行视频剪辑</li>
<li><a href="https://james4ever0.github.io/pyjom_doc">pyjom</a> Social media automation project </li>
<li><a href="https://james4ever0.github.io/PaddleVideo">PaddleVideo</a> Awesome video understanding toolkits based on PaddlePaddle. </li>
<li><a href="https://james4ever0.github.io/google-research">google-research</a> Google Research </li>
</ul>
</li>
<li>Multimodal Transformer<ul>
<li><a href="https://james4ever0.github.io/MultiModalMamba">MultiModalMamba</a> A novel implementation of fusing ViT with Mamba into a fast, agile, and high performance Multi-Modal Model.</li>
<li><a href="https://james4ever0.github.io/Gemini">Gemini</a> The model that will "eclipse ChatGPT"</li>
<li><a href="https://james4ever0.github.io/gato">gato</a> A Generalist Agent </li>
</ul>
</li>
<li>Robotic Transformer<ul>
<li><a href="https://james4ever0.github.io/robo_transformers">robo_transformers</a> Library for Robotic Transformers. RT-1, RT-X-1, Octo</li>
<li><a href="https://james4ever0.github.io/RT-2">RT-2</a> New model translates vision and language into action</li>
<li><a href="https://james4ever0.github.io/AutoRT">AutoRT</a> Embodied Foundation Models for Large Scale Orchestration of Robotic Agents</li>
<li><a href="https://james4ever0.github.io/open_x_embodiment">open_x_embodiment</a> Robotic Learning Datasets and RT-X Models</li>
<li><a href="https://james4ever0.github.io/robotics_transformer">robotics_transformer</a> A collection code files and artifacts for running Robotics Transformer or RT-1.</li>
<li><a href="https://james4ever0.github.io/RT-X">RT-X</a> Pytorch implementation of the models RT-1-X and RT-2-X from the paper: "Open X-Embodiment: Robotic Learning Datasets and RT-X Models" </li>
</ul>
</li>
<li>RAG and Automated Documentation<ul>
<li><a href="https://james4ever0.github.io/my_blog_source">my_blog_source</a> AI assisted blog metadata generator </li>
<li><a href="https://james4ever0.github.io/local_rag">local_rag</a> Chat with Your Multiple PDFs on Your Local System</li>
<li><a href="https://james4ever0.github.io/autodoc">autodoc</a>  Experimental toolkit for auto-generating codebase documentation using LLMs </li>
<li><a href="https://james4ever0.github.io/prometheous_doc">prometheous</a> AI generated documentation and RAG </li>
<li><a href="https://james4ever0.github.io/write-the">write-the</a> AI-powered Documentation and Test Generation Tool </li>
</ul>
</li>
<li>Miscellaneous<ul>
<li><a href="https://james4ever0.github.io/Kacket">Kacket</a> A toy Racket/Scheme code analyzer written in Kotlin.</li>
<li><a href="https://james4ever0.github.io/he4o">he4o</a> HE —— “螺旋熵减机” </li>
</ul>
</li>
</ul>
    </article>
</body>

</html>